{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering with Alternating Least Squares on the Million Song Dataset\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In 2016, more than half of all Americans consumed music through online streaming services on a weekly basis. Online streaming services generated $17.3 billion in revenue in 2017, up 8.1% from 2016. As more listening moves from mp3, AM/FM and physical mediums to streaming, online radio firms are relying on machine learning to rapidly personalize music selection and discovery for users in order to gain a competitive advantage in growing marketplace. Companies such as Spotify and Google have purchased smaller technology start-ups for their audio machine learning solutions (EchoNest) or their extensive customer data (Songza) to get leg up in this digital arms race.\n",
    "\n",
    "Streaming companies utilize a variety of methods to recommend music to their users. Pandora allows users to give songs  a “thumbs up or down” to indicate positive or negative preference. This explicit feedback helps Pandora quickly create personalized playlists, where songs with similar attributes are served to the user based off their rating feedback. Spotify generates playlists based off your listeneing history and factors in everything from time of day to location. With machine learning, a streaming company can use a variety of data to infer a listener’s taste and recommend songs the user is more likely to prefer automatically. Using recommendation systems, companies can create personalized playlists and radio stations without employing taste-makers or experts. \n",
    "\n",
    "### Recommendation Systems\n",
    "\n",
    "Recommendation systems can be broken into two categories: content-based and collaborative filters. Content-based systems rely on attributes related to the item/product (a song or artist in this case) to make recommendations to a user based off known user data. While this approach is effective, it requires storing a large amount of data about the users and items. Often times, companies don't always have customer data to create this type of recommendation system.\n",
    "    \n",
    "A collaborative filter creates a recommendation engine using a user identifier, an item identifier and some rating metric that shows an interaction between the user and item. Based off a collection these user/item interactions, the collaborative filter can predict a user's potential item preference based off users with similar tastes. Similarly, a collaborative filter can infer item similarities. \n",
    "        \n",
    "Collaborative filters can deal with two types ratings data: explicit or implicit. Explicit data means a user has directly made their preference known--similar to Pandora's thumbs up or thumbs down or a 5-star rating system like Yelp's restaurant reviews. Implicit ratings are a feedback metric that does not necessarily give us a user's preference, but we can potentially infer preference--like a product purchase, time spent on a webpage or a song play. A using song plays as an example, a single listen to a song does not necessarily mean the user likes that song, but the more times a user listens to that same song, we can more confidently infer the user has a positive preference for said song. While implicit metrics sacrifice a degree of certainty, implict data is much easier to come by in the real world. \n",
    "    \n",
    "    \n",
    "### The Task\n",
    "\n",
    "The Million Song Challenge (MSC) data set is ideal for creating a recommendation system. Moreover, its format allows us to create a collaborative filter using implicit data. The dataset itself contains over 1 million unique user’s listening data and over 300,000 songs. The task is to create a robust recommendation system with just the interaction between users and songs. As a basis of comparison, we will be comparing the performance of our recommender model to serving the most popular song any given user has not listened to. This is a high bar to clear, as recommending the most popular item tends have a higher accuracy than a recommendation system\n",
    "       \n",
    "Given the structure of the dataset, which is sparse--as most users will have only listened to several songs, and we are dealing with implicit ratings data, I will use an Alternating Least Squares (ALS) algorithm with matrix factorization. \n",
    "    \n",
    "### Matrix Factorization\n",
    "\n",
    "Matrix factorization is a form of latent factor analysis. We start with a sparse matrix M which consists of users by items with ratings metric (song plays) in the cells. With matrix factorization, we factor matrix M into two separate matrices, X and Y; these matrices contain latent factors which reduce large numbers of interactions between users and items into several hidden or unobserved reasons. The X matrix is the users by these hidden features while the Y matrix is the items * hidden factors. Both matrices have a observations which  correspond with either a user or feature from the original matrix M. We then take the product of these matrices to fill in the missing entries of M to provide the liklihood of a user prefering an item.\n",
    "    \n",
    "$$M = XY^T$$\n",
    "    \n",
    "The ALS algorithm is used to find, or approximate, X and Y. Both X and Y aren't known, so values are randomly initialized, first for Y. Then X is solved given the random values of Y and M. Using linear algebra, the algorithm solves for each row of X (i).\n",
    "    \n",
    "$$M_1Y(Y^TY)^{-1} = X_i$$\n",
    "\n",
    "Since the algorithm will not arrive at the exact equivalent, since X and Y are too small/low rank to equal M, values are optimized by minimizing the sum of squared differences between the both matrix entries. \n",
    "    \n",
    "In an implicit scenario, our original matrix M is converted to a binary preference matrix, matrix B. Matrix M is kept to incorporate the positive values as weights. For example, a user who listened to a song 100 times will be said to have more preference than someone who listened to a song 2 times.The equation for deriving the confidence matrix is below:\n",
    "\n",
    "$$C_{ui} = 1 + \\alpha r _{ui}$$\n",
    "\n",
    "\n",
    "$$C_{ui}$$ is the confidence matrix for users and items. $$\\alpha$$ is a scaling value which controls the weight of observed vs. unobserved interactions in the factorization process. $$ r_{ui} is the original matrix, M.\n",
    "\n",
    "ALS minimizes the cost function with the following equation below\n",
    "\n",
    "$$x_u = (Y^TC^uY + \\lambda I)^{-1}Y^TC^up(u)$$\n",
    "\n",
    "Probability of U is the vector of all preferences by u (user) in in binary form. Lambda is the regularization term to avoid overfitting in the training phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevent libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import sys\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import implicit\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training and test data\n",
    "\n",
    "# Training data\n",
    "train = pd.read_csv('train_triplets.txt', delimiter = '\\t', header = None)\n",
    "train.columns = ['users', 'songs', 'play_count']\n",
    "\n",
    "# Test data\n",
    "test = pd.read_csv('kaggle_visible_evaluation_triplets.txt', delimiter = '\\t', header = None, names = ['users', 'songs', 'play_count'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split?\n",
    "\n",
    "Typical machine learning problems involve training an algorithm on a one dataset and then testing the model on a hold-out dataset. This approach will not work here, as we need all possible user-item interactions to optimize our latent factors vectors. We want to reduce the amount of sparsity as much as possible. Instead we will mask a certain percentage of user-item interactions and see if our algorithm correctly predicted if a user preferred that song.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the two dataframe\n",
    "\n",
    "df = pd.concat([train, test], ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track information \n",
    "\n",
    "There is a separate .txt file which maps the song ID from the main dataset to the actual song name and artist name. This information will be useful later when analyzing the results of the data. Viewing the recommendations as songIDs will not be as intuitive as viewing them as a collection of recongnizable songs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cpacewicz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>songs</th>\n",
       "      <th>play_count</th>\n",
       "      <th>song_artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>1</td>\n",
       "      <td>The Cove - Jack Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7c86176941718984fed11b7c0674ff04c029b480</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>1</td>\n",
       "      <td>The Cove - Jack Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76235885b32c4e8c82760c340dc54f9b608d7d7e</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>3</td>\n",
       "      <td>The Cove - Jack Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250c0fa2a77bc6695046e7c47882ecd85c42d748</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>1</td>\n",
       "      <td>The Cove - Jack Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3f73f44560e822344b0fb7c6b463869743eb9860</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>6</td>\n",
       "      <td>The Cove - Jack Johnson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      users               songs  play_count  \\\n",
       "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995           1   \n",
       "1  7c86176941718984fed11b7c0674ff04c029b480  SOAKIMP12A8C130995           1   \n",
       "2  76235885b32c4e8c82760c340dc54f9b608d7d7e  SOAKIMP12A8C130995           3   \n",
       "3  250c0fa2a77bc6695046e7c47882ecd85c42d748  SOAKIMP12A8C130995           1   \n",
       "4  3f73f44560e822344b0fb7c6b463869743eb9860  SOAKIMP12A8C130995           6   \n",
       "\n",
       "               song_artist  \n",
       "0  The Cove - Jack Johnson  \n",
       "1  The Cove - Jack Johnson  \n",
       "2  The Cove - Jack Johnson  \n",
       "3  The Cove - Jack Johnson  \n",
       "4  The Cove - Jack Johnson  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import track and artist information for later analysis\n",
    "\n",
    "track_info = pd.read_csv('unique_tracks.txt', header = None, delimiter = '\\<SEP>', names = ['track_id', 'songs', 'artist', 'song_title'] )\n",
    "\n",
    "# drop duplicates by songID\n",
    "\n",
    "track_info = track_info.drop_duplicates(subset = ['songs'])\n",
    "\n",
    "track_info['song_artist'] = track_info['song_title'] + (\" - \") + track_info['artist']\n",
    "\n",
    "# merge dataframe\n",
    "\n",
    "df_track = df.merge(track_info[['songs', 'song_artist']], on = 'songs', how = 'inner')\n",
    "\n",
    "# check first and last 5 entries of new dataframe\n",
    "\n",
    "df_track.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>songs</th>\n",
       "      <th>play_count</th>\n",
       "      <th>song_artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49824514</th>\n",
       "      <td>a04a1a9855dcbeab1ed2893610340a1da7afc912</td>\n",
       "      <td>SOHNHAR12AB0182868</td>\n",
       "      <td>1</td>\n",
       "      <td>I'll Sing A Sweeter Song Tomorrow - The Deathr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49824515</th>\n",
       "      <td>90f11a614cff00b1b9b6faa4dbba21bea91537ad</td>\n",
       "      <td>SOBXYMP12A6D4F6138</td>\n",
       "      <td>1</td>\n",
       "      <td>Take A Chance - Bill Laswell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49824516</th>\n",
       "      <td>8232bf455c6e53e999c31ee6d042cb07ee6f9c40</td>\n",
       "      <td>SOIYSQG12AB01825DB</td>\n",
       "      <td>2</td>\n",
       "      <td>La Egoista - Diomedes Diaz _ Juancho Rois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49824517</th>\n",
       "      <td>8232bf455c6e53e999c31ee6d042cb07ee6f9c40</td>\n",
       "      <td>SOBIARX12AB0189A77</td>\n",
       "      <td>1</td>\n",
       "      <td>El Parquecito - Diomedes Diaz;Juancho Rois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49824518</th>\n",
       "      <td>53809ef0b5ce3219d46ee6c1a9e37e44b6cebeb0</td>\n",
       "      <td>SOCMDDE12A8C13DDAD</td>\n",
       "      <td>1</td>\n",
       "      <td>TV News - Roger Miret &amp; The Disasters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             users               songs  \\\n",
       "49824514  a04a1a9855dcbeab1ed2893610340a1da7afc912  SOHNHAR12AB0182868   \n",
       "49824515  90f11a614cff00b1b9b6faa4dbba21bea91537ad  SOBXYMP12A6D4F6138   \n",
       "49824516  8232bf455c6e53e999c31ee6d042cb07ee6f9c40  SOIYSQG12AB01825DB   \n",
       "49824517  8232bf455c6e53e999c31ee6d042cb07ee6f9c40  SOBIARX12AB0189A77   \n",
       "49824518  53809ef0b5ce3219d46ee6c1a9e37e44b6cebeb0  SOCMDDE12A8C13DDAD   \n",
       "\n",
       "          play_count                                        song_artist  \n",
       "49824514           1  I'll Sing A Sweeter Song Tomorrow - The Deathr...  \n",
       "49824515           1                       Take A Chance - Bill Laswell  \n",
       "49824516           2          La Egoista - Diomedes Diaz _ Juancho Rois  \n",
       "49824517           1         El Parquecito - Diomedes Diaz;Juancho Rois  \n",
       "49824518           1              TV News - Roger Miret & The Disasters  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_track.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "Unlike more traditional machine learning tasks, the exploratory data analysis phase is limited, since there are relatively few fields. There is still value in performing basic exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    49824519.000000\n",
      "mean            2.876186\n",
      "std             6.456653\n",
      "min             1.000000\n",
      "25%             1.000000\n",
      "50%             1.000000\n",
      "75%             3.000000\n",
      "max          9667.000000\n",
      "Name: play_count, dtype: object\n",
      "Number of unique users: 1129318\n",
      "Number of unique songs: 385371\n",
      "Number of null ratings: 0\n"
     ]
    }
   ],
   "source": [
    "print(df_track['play_count'].describe().apply(lambda x: format(x, 'f')))\n",
    "\n",
    "# How many unique users\n",
    "\n",
    "print(\"Number of unique users: \" + str(len(df_track['users'].drop_duplicates())))\n",
    "\n",
    "# How many unique songs\n",
    "\n",
    "print(\"Number of unique songs: \" + str(len(df_track['songs'].drop_duplicates())))\n",
    "\n",
    "# Check for null values\n",
    "\n",
    "print(\"Number of null ratings: \" + str(df_track['play_count'].isnull().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    play_count\n",
      "song_artist                                                   \n",
      "You're The One - Dwight Yoakam                          762317\n",
      "Undo - Björk                                            681418\n",
      "Revelry - Kings Of Leon                                 552252\n",
      "Sehr kosmisch - Harmonia                                444917\n",
      "Horn Concerto No. 4 in E flat K495: II. Romance...      406995\n",
      "Dog Days Are Over (Radio Edit) - Florence + The...      370812\n",
      "Secrets - OneRepublic                                   305034\n",
      "Canada - Five Iron Frenzy                               284548\n",
      "Invalid - Tub Ring                                      279147\n",
      "Ain't Misbehavin - Sam Cooke                            256340\n",
      "Représente - Alliance Ethnik                            251354\n",
      "Catch You Baby (Steve Pitron & Max Sanna Radio ...      247009\n",
      "Sincerité Et Jalousie - Alliance Ethnik                 234624\n",
      "Hey_ Soul Sister - Train                                217930\n",
      "Fireflies - Charttraxx Karaoke                          205274\n",
      "The Gift - Angels and Airwaves                          200853\n",
      "Tive Sim - Cartola                                      193548\n",
      "Marry Me - Train                                        181411\n",
      "I CAN'T GET STARTED - Ron Carter                        165688\n",
      "Drop The World - Lil Wayne / Eminem                     162927\n",
      "OMG - Usher featuring will.i.am                         162307\n",
      "Make Love To Your Mind - Bill Withers                   153629\n",
      "Use Somebody - Kings Of Leon                            151188\n",
      "Almaz - Randy Crawford                                  135430\n",
      "Mercy:The Laundromat - Pavement                         135235\n",
      "16 Candles - The Crests                                 134850\n",
      "The Scientist - Coldplay                                133398\n",
      "Lucky (Album Version) - Jason Mraz & Colbie Cai...      132022\n",
      "Pursuit Of Happiness (nightmare) - Kid Cudi / M...      129119\n",
      "Billionaire [feat. Bruno Mars]  (Explicit Album...      127313\n",
      "...                                                        ...\n",
      "Paris Hilton (Beam VS Egohead Deluxe Edit) - Ci...           1\n",
      "Paris Groove - The Rippingtons                               1\n",
      "When The Time Comes (Stand Album Version) - Avalon           1\n",
      "The Legend Of Buddy Bolden - Wynton Marsalis Se...           1\n",
      "Still Dreaming (radio edit) - Madi Simmons                   1\n",
      "The Legend Of Bebop (LP Version) - Ornette Coleman           1\n",
      "Da Hoola Jacknife Lee - Telepopmusik                         1\n",
      "Mistreatin Me - Cedell Davis                                 1\n",
      "Mistreated - Groundhogs                                      1\n",
      "I Won't Forget You - Punkrockerz                             1\n",
      "Parlez Nous A Boire - Lil' Band O' Gold                      1\n",
      "Da Dove Vieni - Flaminio Maphia                              1\n",
      "Da Draussen Am Hafen - Lale Andersen                         1\n",
      "Uncreation - 1349                                            1\n",
      "Da Folliña Dunha Rosa - Camerata Meiga                       1\n",
      "I Won\u0019t Stand In Your Way - Eddi Reader                      1\n",
      "Friend Of The Devil (Live) - DAVID GRISMAN AND ...           1\n",
      "Still Alive (Album Version) - Joe Jackson Band               1\n",
      "Kick The Bong Around (Shooting Crack with Broth...           1\n",
      "Amor Perfecto - Margarita                                    1\n",
      "Amor Perdido - Maria Luisa Landin;Orquesta De J...           1\n",
      "Mistic funeral - Xiii. Stoleti                               1\n",
      "Boredom Is The Feeling That Everything Is A Was...           1\n",
      "Bassdusche (Can You Feel It?) (Beam Vs. Cyrus R...           1\n",
      "Und diese Rosen sind für Dich_ liebe Mamatschi ...           1\n",
      "I Won't Compromise - Keith Hudson                            1\n",
      "Park My Car - Down To Nothing                                1\n",
      "Und ich bring dir die Hölle - Stahlhammer                    1\n",
      "Friend - The Sleepover Disaster                              1\n",
      "Seethrustars - Air Formation                                 1\n",
      "\n",
      "[381556 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check top played songs\n",
    "\n",
    "song_pivot = df_track.pivot_table(index = 'song_artist',\n",
    "                                  values = \"play_count\",\n",
    "                                  aggfunc = sum)\n",
    "\n",
    "print(song_pivot.sort_values('play_count', ascending= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    1.0\n",
      "0.1    1.0\n",
      "0.2    1.0\n",
      "0.3    1.0\n",
      "0.4    1.0\n",
      "0.5    1.0\n",
      "0.6    2.0\n",
      "0.7    2.0\n",
      "0.8    3.0\n",
      "0.9    6.0\n",
      "Name: play_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check distribution\n",
    "\n",
    "print(df_track['play_count'].quantile(np.arange(0,1,0.1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cpacewicz/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histogram for distribution\n",
    "_ = plt.hist(df_track['play_count'],  bins = 8, range = [1, 40], normed = True )\n",
    "_ = plt.ylabel('Counts')\n",
    "_ = plt.xlabel('# of Plays')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "The ALS algorithm requires that our data be in the form of a sparse matrix of users * items with interactions (play count) in the cells. Therefore, we will create a sparse matrix with the relevent columns. We must also encode the user and item variables for faster processing. We will map these codes to the song title and artist name for interpreting our model at a later point. \n",
    "\n",
    "While performing preprocessing, we will also check the sparsity of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode relevent variables\n",
    "\n",
    "df_track['user_id'] = df_track['users'].astype(\"category\").cat.codes\n",
    "df_track['song_id'] = df_track['songs'].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sparsity: 0.9998855151987629\n"
     ]
    }
   ],
   "source": [
    "# Create sparse matrix of user * item interactions\n",
    "\n",
    "sp_item_user = sp.csr_matrix((df_track['play_count'].astype(float), (df_track['song_id'], df_track['user_id'])))\n",
    "\n",
    "# Calculate density\n",
    "\n",
    "sparsity = 1-(df_track.shape[0] / (df_track.user_id.unique().shape[0] * df_track.song_id.unique().shape[0]))\n",
    "print(\"Total Sparsity: \" + str(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Recommendation Efficacy\n",
    "\n",
    "As previously mentioned, using a traditional test-train split will not work for our purposes. We will use a function that masks a certain percentage of user-item interactions on a validation set of data. After creating our recommender, we will check to see if our model ended up serving songs the user already listened to in the masked entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_mask(sp_matrix, test_split = 0.1):\n",
    "  \n",
    "    val_set = sp_matrix.copy() # make test set from train data \n",
    "    val_set[val_set != 0] = 1 # Create unary matrix, all interactions\n",
    "    train = sp_matrix.copy() # train set where certain interactions will be hidden\n",
    "    nonzero_inds = train.nonzero() # use nonzero method to store user/items with interactions\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # list of user/song interactions that aren't zero\n",
    "    random.seed(123) # set random seed for reproducability\n",
    "    mask_number = int(np.rint(test_split*len(nonzero_pairs))) #  # of samples\n",
    "    masked = random.sample(nonzero_pairs, mask_number) # Sample a random number of user-item pairs (no replacement)\n",
    "    item_inds = [index[0] for index in masked] # All song column indices\n",
    "    user_inds = [index[1] for index in masked] # All user row indices\n",
    "    train[item_inds, user_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero thereby masking them\n",
    "    train.eliminate_zeros() # Delete zeros in sparse array storage after update to save space\n",
    "    return train, val_set, list(set(item_inds)) # returns unique group of masked items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val_set, masked_list = train_test_mask(sp_item_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "\n",
    "A python package called Implicit is a great out-of-the-box option for creating a collaborative filter using the ALS method. This package uses Cython for processing code with different threads and the syntax is very straightforward. The hyperparameters are alpha, which is a scaling value for our ratings matrix, regularization, an overfitting parameter, number of factors, the number of hidden or latent factors and iterations, which is the number of times to switch between the user and item matrices in the alternating least squares process. We used the basic parameters here (hyperparameter tuning is restricted here due to memory constraints--see next section in Spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n",
      "100%|██████████| 20.0/20 [10:03<00:00, 30.89s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use alternating Least Squares to create recommendation algorithm\n",
    "\n",
    "alpha = 15\n",
    "rec = implicit.als.AlternatingLeastSquares(factors = 20, regularization = 0.1,\n",
    "                                           iterations = 20) \n",
    "rec.fit(train * alpha)\n",
    "\n",
    "# Create latent features object for users and items respectively \n",
    "item_vec, user_vec_t = rec.item_factors, rec.user_factors.transpose() # transpose for matrix operations\n",
    "\n",
    "# create user item sparse matrix for looking up recommendations results\n",
    "sp_user_item = sp_item_user.T.tocsr()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songs</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elephant Gun - Beirut</td>\n",
       "      <td>0.161170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There Is A Light That Never Goes Out - The Smiths</td>\n",
       "      <td>0.158865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quelqu'un M'a Dit (Album Version) - Carla Bruni</td>\n",
       "      <td>0.154508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wild World - Cat Stevens</td>\n",
       "      <td>0.151159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boys Don't Cry - The Cure</td>\n",
       "      <td>0.150795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Heartbeats - José Gonzalez</td>\n",
       "      <td>0.143932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nantes - Beirut</td>\n",
       "      <td>0.139389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Am I A Fool - Sense Field</td>\n",
       "      <td>0.138196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between The Bars - Elliott Smith</td>\n",
       "      <td>0.137535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sehr kosmisch - Harmonia</td>\n",
       "      <td>0.135473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               songs     score\n",
       "0                              Elephant Gun - Beirut  0.161170\n",
       "1  There Is A Light That Never Goes Out - The Smiths  0.158865\n",
       "2    Quelqu'un M'a Dit (Album Version) - Carla Bruni  0.154508\n",
       "3                           Wild World - Cat Stevens  0.151159\n",
       "4                          Boys Don't Cry - The Cure  0.150795\n",
       "5                         Heartbeats - José Gonzalez  0.143932\n",
       "6                                    Nantes - Beirut  0.139389\n",
       "7                          Am I A Fool - Sense Field  0.138196\n",
       "8                   Between The Bars - Elliott Smith  0.137535\n",
       "9                           Sehr kosmisch - Harmonia  0.135473"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Spot check recommendations for a user\n",
    "\n",
    "# Choose user (arbitrary)\n",
    "user = 10\n",
    "\n",
    "# Function to return a dataframe of song recommendations\n",
    "def user_recommendations(user, sp_matrix):\n",
    "    songs = []   # create list for recommended songs\n",
    "    scores = []  #  store recommendation scors\n",
    "    recommended_songs = rec.recommend(user, sp_matrix)  # use implicit recommend function\n",
    "    for song in recommended_songs:\n",
    "        idx, score = song    # store index and score of song\n",
    "        songs.append(df_track.song_artist.loc[df_track.song_id == idx].iloc[0])   # use song index to append song title and artist name\n",
    "        scores.append(score)   # append score to list\n",
    "        \n",
    "        recommendations = pd.DataFrame({'songs': songs, 'score': scores})      # create dataframe of results\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "user_recommendations(user, sp_user_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Recommendation Efficacy continued\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area under the curve (AUC) score function\n",
    "\n",
    "def auc_score(pred, actual):\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(actual, pred)\n",
    "    return metrics.auc(fpr, tpr)  \n",
    "\n",
    "\n",
    "\n",
    "# Creating ROC curve and evaluating our model against a naive model which serves the most popular song the user has not previously listened to\n",
    "# by comparing the AUC scores\n",
    "\n",
    "def area_under_curve(training_set, masked_list, predictions, val_set):\n",
    "\n",
    "    \n",
    "    als_auc = [] # list for item that\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_items = np.array(val_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    vec1 = predictions[1]\n",
    "    with tqdm(total=len(masked_list), file=sys.stdout) as pbar:\n",
    "        for index, user in enumerate(masked_list): # Iterate through each user that had an item altered\n",
    "            training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
    "            zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "            # Get the predicted values based on our user/item vectors\n",
    "            vec2 = predictions[0][user,:]\n",
    "            pred = vec2.dot(vec1).toarray()[0,zero_inds].reshape(-1)\n",
    "            # Get only the items that were originally zero\n",
    "            # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "            actual = val_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "            # take the unary 1/0 interaction pairs from the original matrix\n",
    "            # which align with the same pairs in train set \n",
    "            pop = pop_items[zero_inds] # Get most popular item\n",
    "            als_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user\n",
    "            popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular\n",
    "            #pbar.set_description('processed: %d als_auc: %d percent pop_auc: %d percent' % (1 + index, 100 * np.mean(als_auc), (100 * np.mean(popularity_auc))))\n",
    "            pbar.update(1)\n",
    "        \n",
    "    \n",
    "    return float('%.3f'%np.mean(als_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "   # Return the mean AUC for our model and the most popular item for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe9c0cabbb0445e8cb93af55e8c910d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.827, 0.771)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "area_under_curve(train, masked_list[:30000], \n",
    "              [sp.csr_matrix(item_vec), sp.csr_matrix(user_vec_t)], val_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning our Model\n",
    "\n",
    "Our model outperformed serving the most popular song on a subset of 1000 altered entries, but neither recommendation system was particularly high.\n",
    "\n",
    "An issue with the initial model is the overall sparsity of of our item * user matrix. In order to tune our model further, we will reduce the sparsity of our model by removing users and items below a certain threshold of interactions.  Our dataset as is has a sparisty level of 99.98%. Therefore we will remove all users who have listened below x number of songs and songs not listened to until our model reaches our model is less than 99.95% sparse. This will remove a large amount of data, but will make our recommender more robust. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode relevent variables on original dataset\n",
    "df['user_id'] = df['users'].astype(\"category\").cat.codes\n",
    "df['song_id'] = df['songs'].astype(\"category\").cat.codes\n",
    "\n",
    "df = df[['user_id', 'song_id', 'play_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to remove users and songs below certain number of interactions\n",
    "def activity_thresh(df, user_min, song_min):\n",
    "    while True:\n",
    "        start_dim = df.shape[0]\n",
    "        song_counts = df.groupby('user_id').song_id.count()\n",
    "        df = df[~df.user_id.isin(song_counts[song_counts < song_min].index.tolist())]\n",
    "        user_counts = df.groupby('song_id').user_id.count()\n",
    "        df = df[~df.song_id.isin(user_counts[user_counts < user_min].index.tolist())]\n",
    "        end_dim = df.shape[0]\n",
    "        if start_dim == end_dim:\n",
    "            break\n",
    "    n_users = df.user_id.unique().shape[0]\n",
    "    n_items = df.song_id.unique().shape[0]\n",
    "    sparsity = 1- (float(df.shape[0]) / float(n_users*n_items))\n",
    "    print('Number of users: {}'.format(n_users))\n",
    "    print('Number of songs: {}'.format(n_items))\n",
    "    print('Sparsity: {:.5%}'.format(sparsity))\n",
    "    return df, sparsity\n",
    "\n",
    "\n",
    "# Create a loop that stops at a certain sparsity threshold\n",
    "#for i in range(25,50,2):\n",
    "#    print('Min user and song count: {}'.format(i))\n",
    "#    _, sparsity = activity_thresh(df, i, i)\n",
    "#    if sparsity < 0.9995:\n",
    "#        break\n",
    "#    else:\n",
    "#        continue\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 548135\n",
      "Number of songs: 131637\n",
      "Sparsity: 99.94577%\n"
     ]
    }
   ],
   "source": [
    "# Create a reduced dataframe \n",
    "df_red, _ = activity_thresh(df, 25, 25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create item/user and user/item sparse matrices\n",
    "sp_item_user = sp.csr_matrix((df_red['play_count'].astype(float), (df_red['user_id'], df_red['song_id'])))\n",
    "\n",
    "\n",
    "# Creating the second version of our model\n",
    "train_2, val_set_2, masked_list_2 = train_test_mask(sp_item_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20.0/20 [10:24<00:00, 30.54s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use alternating Least Squares to create recommendation algorithm--add 50 factors now as well\n",
    "\n",
    "alpha = 15\n",
    "rec2 = implicit.als.AlternatingLeastSquares(factors = 50, regularization = 0.1,\n",
    "                                           iterations = 20)\n",
    "rec2.fit(train_2 * alpha)\n",
    "\n",
    "\n",
    "item_vec_2, user_vec_t_2 = rec2.item_factors, rec2.user_factors.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b235b8ca9bd340b6ae77d8bb9d49e3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.95, 0.952)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create another model with the \n",
    "area_under_curve(train_2, masked_list_2[:30000], \n",
    "              [sp.csr_matrix(item_vec_2), sp.csr_matrix(user_vec_t_2)], val_set_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts -- Next Steps\n",
    "\n",
    "The AUC score improved after removing user/item interactions below a threshold of 25. To improve our model further, the hyperparameters of the ALS algorithm will need to be tuned. However, this requires more computing power than a standard desktop allows for--running the AUC curve function took ~2 days on my machine. The most expedient way to improve this model would be to use a distributed framework like Spark. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "- Recommender Systems; Charu C. Aggarwal; 2016\n",
    "- Advanced Analytics with Spark; Sean Owen; 2017\n",
    "- http://yifanhu.net/PUB/cf.pdf\n",
    "- https://jessesw.com/Rec-System/\n",
    "- https://github.com/benfred/implicit\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

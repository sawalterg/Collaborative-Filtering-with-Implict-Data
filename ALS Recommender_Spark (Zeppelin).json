{"paragraphs":[{"text":"// version check and test\nsc.version\n\n\nval projectDirectory = new java.io.File(\".\").getCanonicalPath\n\n\n// import two data frames as RDD\nval train = sc.textFile(\"file:///../Downloads/train_triplets.txt\")\n\nval test = sc.textFile(\"file:///../Downloads/kaggle_visible_evaluation_triplets.txt\")\n\n//concatenate the train and test\nval combRDD = train.union(test)\n\n//print the first 5 lines\ncombRDD.take(5).foreach(println)\n\n\n// convert RDD to dataframe\nval rawcombDF = combRDD.map { line =>\n    val Array(user, song, count) = line.split('\\t')\n    (user, song, count.toInt)\n}.toDF(\"user\", \"song\", \"count\")\n\n// spot check columns and header as dataframe\nrawcombDF.columns\nrawcombDF.head\n\n\n","user":"anonymous","dateUpdated":"2018-11-11T18:11:43-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1540604820607_-417742052","id":"20181026-214700_1272270370","dateCreated":"2018-10-26T21:47:00-0400","dateStarted":"2018-11-11T18:11:44-0500","dateFinished":"2018-11-11T18:11:44-0500","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3989"},{"text":"import org.apache.spark.ml.feature.StringIndexer\n\n\n// create string indexer object for encoding userids into numerical values\n\nval stringindexer = new StringIndexer().\n    setInputCol(\"user\").\n    setOutputCol(\"userID\").\n    setHandleInvalid(\"keep\") // keep and index new labels\n\n// fit and transform with indexer\n\nval combDF = stringindexer.fit(rawcombDF).transform(rawcombDF)\n\n\n// create second object for converting songid into index -- don't use same object for different columns\nval stringindexer2 = new StringIndexer().\n    setInputCol(\"song\").\n    setOutputCol(\"songID\").\n    setHandleInvalid(\"keep\")\n    \n// fit the indexer to song -- don't transform, as we will need the same mapping values for our song id to song mapper\n    \nval indexerModelSong = stringindexer2.fit(combDF)\n\nval combDF2 = indexerModelSong.transform(combDF)\n\nval df = combDF2.select(\"userID\", \"songID\", \"count\")","user":"anonymous","dateUpdated":"2018-11-08T01:06:31-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1540847643035_-396759101","id":"20181029-171403_1113994084","dateCreated":"2018-10-29T17:14:03-0400","dateStarted":"2018-11-08T01:06:31-0500","dateFinished":"2018-11-08T01:08:46-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3990"},{"text":" import org.apache.spark.sql.functions.{concat, lit}\n\n// import artist and song data to match with song ID\n\nval rawArtistSongData = sc.textFile(\"file:///Users/cpacewicz/Downloads/unique_tracks.txt\")\n\nval songIDtotitle = rawArtistSongData.map { line =>\n    val Array(track, song, artist, title) = line.split(\"<SEP>\")\n    (track, song, artist, title)\n}.toDF(\"track\",\"song\", \"artist\", \"title\")\n\n\nsongIDtotitle.printSchema()\n\nimport org.apache.spark.sql.functions.{concat, lit}\n\n// import artist and song data to match with song ID\n\nval editedSongArtist = songIDtotitle.withColumn(\"songArtist\", concat(col(\"title\"), lit(\" , \"), col(\"artist\")))\n\n\nval rawSongMap = indexerModelSong.transform(editedSongArtist)\n\nval finalSongMap = rawSongMap.select(\"songID\", \"songArtist\")\n\nfinalSongMap.show()\n\n","user":"anonymous","dateUpdated":"2018-11-08T01:22:24-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541375932439_1557022174","id":"20181104-185852_940066523","dateCreated":"2018-11-04T18:58:52-0500","dateStarted":"2018-11-08T01:22:24-0500","dateFinished":"2018-11-08T01:22:33-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3991"},{"text":"//cache df for processing\n\ndf.cache()\n\ndf.show()","user":"anonymous","dateUpdated":"2018-11-08T01:22:53-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1540748779169_299116919","id":"20181028-134619_1992096367","dateCreated":"2018-10-28T13:46:19-0400","dateStarted":"2018-11-08T01:22:53-0500","dateFinished":"2018-11-08T01:23:16-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3992"},{"text":"import org.apache.spark.ml.recommendation._\n\nval model = new ALS().\n    setSeed(12).\n    setImplicitPrefs(true).\n    setRank(10).\n    setRegParam(0.01).\n    setAlpha(1.0).\n    setMaxIter(2).\n    setUserCol(\"userID\").\n    setItemCol(\"songID\").\n    setRatingCol(\"count\").\n    setPredictionCol(\"prediction\").\n    fit(df)","user":"anonymous","dateUpdated":"2018-11-08T01:32:44-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1540768313948_-592627618","id":"20181028-191153_1423742600","dateCreated":"2018-10-28T19:11:53-0400","dateStarted":"2018-11-08T01:32:44-0500","dateFinished":"2018-11-08T01:32:44-0500","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3993"},{"text":"//spot checking recommendations\n\nmodel.userFactors.show(0, truncate = False)\n\nval randUser = 17\n\nval exisitingSongIDs = df.\n    filter($\"userID\" == randUser).\n    select(\"songID\").as[Int].collect()\n\nfinalSongMap.filter($\"songID\" isin (existingSongIDs:_*)).show()","user":"anonymous","dateUpdated":"2018-11-08T00:42:56-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1540769072421_128654507","id":"20181028-192432_1356291479","dateCreated":"2018-10-28T19:24:32-0400","dateStarted":"2018-11-08T00:42:56-0500","dateFinished":"2018-11-08T00:42:56-0500","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3994"},{"text":"// Create a function for serving top recommendations for any given user\n\ndef recommender(\n    model: ALSModel,\n    userID: Int,\n    howMany: Int): DataFrame = {\n        \n    val recommendation = model.itemFactors.\n        select($\"songID\".as(\"song\")).\n        withColumn(\"userID\", lit(\"UserID\"))\n        \n    model.transform(recommendation).\n        select(\"song\", \"prediction\").\n        orderBy($\"prediction\".desc).\n        limit(howMany)\n    }","user":"anonymous","dateUpdated":"2018-11-04T21:16:23-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541127074224_85849993","id":"20181101-225114_200613088","dateCreated":"2018-11-01T22:51:14-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3995"},{"text":"// call the function to check a user's top recommended songs\n\nval topRecommendations = recommender(model, randUser, 20)\ntopRecommendations.show()\n\nval recommendedSongIDs = \n    topRecommendations.select(\"songID\").as[Int].collect()\n    \nsongIDtotitle.filter($\"songID\" isin (recommendedSongIDs:_*)).show()","user":"anonymous","dateUpdated":"2018-11-04T21:16:57-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541127677878_169396462","id":"20181101-230117_1369323219","dateCreated":"2018-11-01T23:01:17-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3996"},{"text":"// use ROC curve and measure our ALS model's performance against the most popular song\n\ndef AUC(\n    positiveData: DataFrame,\n    bAllSongIDs: Broadcast[Array[Int]],\n    predictFunction: (DataFrame => DataFrame)): Double = {\n        \n    }\n    \nval allData = df\nval Array(df, cvData) = allData.randomSplit(Array(0.9), 0.1))\ndf.cache()\ncvData.cache()\n\nval allSongIDs = allData.select(\"songID\").as[Int].distinct().collect()\n\nval bAllSongIDs = spark.sparkContext.broadcast(finalSongMap)\n\n\nval model2 = new ALS().\n    setSeed(Random.nextLong()).\n    setImplicitPrefs(true).\n    setRank(10).setRegParam(0.01).setAlpha(1.0).setMaxIter(5).\n    setUserCol(\"userID\").setItemCol(\"songID\").\n    setRatingCol(\"count\").setPredictionCol(\"prediction\").\n    fit(combDF)\n\nAUC(cvData, bAllSongIDs, model2.transform)","user":"anonymous","dateUpdated":"2018-11-07T21:19:42-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541127682201_-1378651003","id":"20181101-230122_678823781","dateCreated":"2018-11-01T23:01:22-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3997"},{"text":"def predictMostListened(train: DataFrame)(allData: DataFrame) = {\n    \n    val playcounts = train.\n        groupBy(\"songID\").\n        agg(sum(\"count\").as(\"prediction\")).\n        select(\"songID\", \"prediction\")\n        \n        \n    allData.\n        join(playcounts, Seq(\"songID\"), \"left_outer\").\n        select(\"userID\", \"songID\", \"prediction\")\n}\n\nAUC(cvData, bAllSongIDs, predictMostListened(trainData))\n","user":"anonymous","dateUpdated":"2018-11-07T21:19:31-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541128293753_-943787780","id":"20181101-231133_669176519","dateCreated":"2018-11-01T23:11:33-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3998"},{"text":"\n// Hyperparameter tuning\n\nval evaluations = \n    for (rank   <- Seq(5, 30);\n        regParam <- Seq(2.0, 0.0001);\n        alpha    <- Seq(1.0, 30.0))\n    yield {\n        val model3 = new ALS().\n        setSeed(Random.nextLong()).\n        setImplictPrefs(true).\n        setRank(rank).setRegParam(regParam).\n        setAlpha(alpha).setMaxIter(20).\n        setUserCol(\"userID\").setItemCol(\"songID\").\n        setRatingCol(\"count\").setPredictionCol(\"prediction\").\n        fit(trainData)\n        \n        \n        val auc = AUC(cvData, bAllSongIDs, model3.transform)\n        \n        model3.userFactors.unpersist()\n        model3.itemFactors.unpersist()\n        \n        (auc, (rank, regParam, alpha))\n    }\n\n// print out a sorted list of hyperparameters based on highest AUC\n    \nevaluations.sorted.reverse.foreach(println)","user":"anonymous","dateUpdated":"2018-11-07T21:19:18-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541128293071_227462193","id":"20181101-231133_431554947","dateCreated":"2018-11-01T23:11:33-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3999"},{"text":"// Give recommendations\n\nval randUsers = allData.select(\"useIDr\").as[Int].distinct().take(50)\n\nval recommender2 =\n    randUsers.map(userID => (userID, makeRecommendations(model3, userID, 5)))\nrecommender2.foreach { case (userID, recDF) +>\n    val recommendedSongs = recDF.select(\"songID\").as[Int].collect()\n    println(s\"$userID\" -> ${recommendedSongs.mkString(\", \")}\"\")\n    \n}\n\n","user":"anonymous","dateUpdated":"2018-11-04T21:22:35-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541128292309_-1174047144","id":"20181101-231132_901748678","dateCreated":"2018-11-01T23:11:32-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4000"},{"text":"rawSongData.map { line => \n    val (id, name) = line.span(_ != '\\t')\n    (name.trim, id.int)\n}","user":"anonymous","dateUpdated":"2018-11-01T23:49:14-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541130469265_58098923","id":"20181101-234749_1032632012","dateCreated":"2018-11-01T23:47:49-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4001"}],"name":"ALS Recommender","id":"2DWNYABXC","noteParams":{},"noteForms":{},"angularObjects":{"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}